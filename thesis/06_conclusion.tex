\chapter{Discussion and Future Work}
\label{conclusion}
In this work, we explored the feasibility of the tasks of table detection and table classification for historical newspapers. Both tasks have been approached from several angles, which we summarize in this section. For each of them, we discuss the possible shortcomings of our approach and give some hints for solving them. We also expand on the discoveries made during the development of this thesis and give some directions for future work to build on them. \\

The first part of this project focused on the experimentation and comparison of two image segmentation methods for table detection in historical newspaper pages. During the development of this comparison, it became apparent that the dataset on which it was to be performed was inconsistently labelled and needed to be addressed. This first comparison therefore paved the way in understanding to what extent these two models can perform well with noisy data. In this regard, evaluating an object instance segmentation algorithm as if it were a semantic image segmentation algorithm proved to be a sound choice as the performance of Mask R-CNN trained on inconsistent data exceeded our expectations. Nevertheless, we believe that its performance could be further investigated, as some of its worst predictions could be filtered by setting a threshold to their confidence scores. Possible additional performance could result from this. We are concerned, however, that Mask R-CNN may not reiterate its performance on a slightly more out-of-domain dataset. Indeed, the output of Mask R-CNN could be investigated to see if it correctly detected all the tables that were ever annotated in the original dataset, and if it was unable to detect those that were not, or if it really understood what a table is.  \\
With this in mind, as suggested by \citet{casado-garcia_benefits_2020}, it would be interesting to see if the performance of the models can be increased by pre-training on a more closely related domain. This aspect was lightly explored in this thesis, as a dataset consisting of tables from ICDAR 2019 \citep{gao_icdar_2019} was used to pre-train dhSegment; however, the first results when looking at the validation loss during training seemed to be going at a slower pace than when it was not pre-trained. This was deemed unsatisfactory and the experiment was aborted, but also due to lack of time we knew this strategy could not be thoroughly tested. Retrospectively, we believe the dataset may have been slightly off-domain as its tables tend to cover large part of the image which is unlike newspapers, and there also seems to be a lack of diversity. We believe that a dataset like TableBank \citep{li_tablebank_2020} would be more suitable due to its large size and the diversity of table sizes. However, training models on this dataset would be very time-consuming due to its size.\\
Although the results were satisfactory, we investigated whether it was possible to mitigate the noise in the dataset by developing a filtering strategy based on manually identifying problematic clusters of mislabelled pages. These pages were noticed after conducting a manual survey by re-annotating some pages and establishing statistics on them. This strategy turned out to be relevant for dhSegment, indicating that it could be studied further. However, in the later stages of this thesis, we came across a noteworthy paper by \citet{petit_handling_2018} who propose a way to handle missing annotations for semantic segmentation, thus dealing with inconsistent ground truth, by incremental self-supervision and relabelling. We think this could be an interesting direction to investigate.\\

The second part of the work explored the classification of tables. We first compared the ability of three different models that use different data modalities and established the importance of the layout modality for our task. The differences in performance with a text only based model were quite large, leading us to believe that this model may have been under-trained. Nevertheless, the comparison was done fairly because all models saw the same amount of tables. To properly evaluate the difference between the modalities, it certainly would have been better to run optical character recognition on the tables again, to ensure that the text modality is used to its full potential. Despite this, we have found that using text, layout and image information generates excellent predictions, so much so that we believe these models could be directly applied to the existing segmentation of \textit{impresso}. By manually labelling a diverse dataset that might even include items that are not tables, and re-training these models on that basis, we believe they could generate excellent classification results. \\
In a final step, we also explored a strategy to automatically augment a manually labelled dataset and assessed its quality and relevance. This further improved the performance of all classifiers, on a representative test set. Here, we think it would be important to create a rather different test set, e.g. based on other newspapers, to confirm that this strategy is successful. If this is the case, one could reuse this augmentation strategy on the predictions of the classifiers to iteratively increase the amount of labelled data. Another aspect that could be studied is to see if there is an interest in lowering the visual similarity threshold and test if performance of the classifiers can be further improved. \\

Finally, now that we know that tables can be effectively segmented at the object instance level if the dataset is correctly labelled, we could stack the models trained here, i.e. Mask R-CNN and one of the classifiers, and evaluate the complete pipeline for table detection and classification. Another option to be explored would be to build on the work of \citet{barman_combining_2021} and incorporate the layout modality, which has been shown to be relevant for classification, into dhSegment-text and solve the tasks of table detection and classification in an end-to-end manner.\\
Overall, we believe that this project has successfully addressed the two tasks of table detection and classification, showing that these tasks are well within reach in the context of historical newspapers. The quality of the data at disposal turned out to be somewhat underwhelming and brought its share of questions and challenges throughout the project. These have been addressed too, but more work could be done around these issues in order to construct more coherent datasets. Nevertheless, we believe that further tasks around tables, such as table recognition, can now be explored. \\

All the code developed as well as the models trained during this project can be found online in the code repository of \textit{impresso}\footnote{\url{https://github.com/impresso/impresso-table-processing}}.
