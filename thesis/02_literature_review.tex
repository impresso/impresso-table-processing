\chapter{Literature Review}
\label{literature_review}
This section introduces some of the latest deep learning (DL) approaches to \textit{document layout analysis}. First, we cover some of the recent breakthroughs in computer vision (CV) and natural language processing (NLP), and how image and text modalities started to be combined; we then relate these to the tasks of \textit{table detection} and \textit{table classification}. Finally, we present some of the datasets that have been built over the years to address and evaluate document-related problems.

\paragraph{Document Layout Analysis}
Recent DL models for CV based on convolutional neural networks (CNN), such as YOLO \citep{redmon_you_2016}, Faster R-CNN \citep{ren_faster_2016}, DeepLab \citep{chen_deeplab_2017}, Mask R-CNN \citep{huang_mask_2019} or Cascade R-CNN \citep{cai_cascade_2021}, have found use for document-related tasks. Some image segmentation models, like dhSegment \citep{ares_oliveira_dhsegment_2018}, were even specifically developed for document images. dhSegment is based on the deep residual ResNet architecture \citep{he_deep_2015} and has notably shown good results for historical documents. Actually, most of the visual models aimed at document images use one of the aforementioned models as part of their architecture.  \\
All these models aim at solving the task of image segmentation which corresponds to the partitioning of images into regions of interest. Image segmentation methods are usually classified in three categories: i) semantic segmentation, which refers to the task of predicting the semantic class each pixel of an image belongs to (DeepLab and dhSegment are semantic image segmentation algorithms); ii) object instance segmentation, which aims at detecting clusters of pixels belonging to the same semantic class and at identifying each instance of the class separately (Mask R-CNN and YOLO are examples of object instance image segmentation algorithms); and iii) panoptic segmentation, which consists of a mixture of the above tasks, where a class and an instance of that class must be assigned to each pixel.\\
In terms of NLP, DL has also allowed great advances. One can mention the transformer architecture \citep{vaswani_attention_2017}, extensively used for language models such as GPT \citep{brown_language_2020} or BERT \citep{devlin_bert_2019} which are the basis of many other language models. To name a few, RoBERTa \citep{liu_roberta_2019} revises the pre-training of BERT, whereas LAMBERT \citep{garncarek_lambert_2021} uses layout features in addition to textual features. The latter is part of a growing category of models that has shown state-of-the-art results on document processing tasks. In addition to textual features in the form of word embeddings, these models uses layout features, i.e. word bounding box coordinates obtained by Optical Character Recognition (OCR), as well as visual features, i.e. image region of words. As an example, we can cite the family of models consisting of LayoutLM \citep{xu_layoutlm_2019}, LayoutLMv2 \citep{xu_layoutlmv2_2021} and LayoutXLM \citep{xu_layoutxlm_2021}, which incorporate both modalities. LayoutLMv2 improves on its predecessor by integrating visual embeddings during pre-training, while LayoutXLM brings some robustness by training on multilingual documents. In terms of multi-modal models specifically designed for document layout analysis, we can also cite VSR (Visual, Semantics and Relations) \citep{zhang_vsr_2021}, which combines two CNNs for visual and textual feature extraction by adaptively aggregating them before feeding them to a graph-based relationship module which outputs the predictions. Similarly, \citet{barman_combining_2021} -- on which this Master's thesis builds upon -- adds textual features to dhSegment and shows a performance increase for historical newspaper layout analysis tasks.\\
Finally, in the context of document layout analysis, one should also mention LayoutParser by \citet{shen_layoutparser_2021}, a library which aims at increasing the accessibility and usability of some of the architectures and models previously mentioned. It offers a model zoo with models pre-trained on document image datasets, which can either be used as is or fine-tuned, i.e. re-trained on a generally smaller but more specific dataset with a possibly different set of labels.

\paragraph{Table detection}
The survey of \citet{hashmi_current_2021} describes the current state of the research for the task of \textit{table recognition} using DL methods and defines it as the ``structural segmentation and parsing information of table cells''. It comes after the tasks of \textit{table detection} and \textit{table structural recognition}, which are defined to as ``detecting the tabular boundaries in terms of bounding boxes in document images'' and ``defining the structure of table by analyzing information of row and column layouts''. This thesis adopts these definitions, with some leeway for \textit{table detection}: boundaries can be defined not only on the basis of bounding boxes but also by segmentation masks, as tables in newspapers sometimes spread on non-contiguous regions or are simply not rectangular making bounding boxes a poor choice to capture such case. \\
Many CNN-based models have been developed to tackle the task of table detection in document images. The first models, such as \citet{gilani_table_2017} and \citet{schreiber_deepdesrt_2017}, are almost all based on Faster R-CNN. \citet{sun_faster_2019} proposed a refined Faster R-CNN-based model which not only detects tables but also table corners. At the cost of additional detections required and extra post-processing steps, this method yielded better results than the two previous models. YOLO-based models exist too. \citet{huang_yolo-based_2019} proposed a modification of YOLOv3 \citep{redmon_yolov3_2018} including anchor optimization for document tables. Anchor is a concept used in object detection algorithms, where regions are not generated by the network directly but rather from predicted offsets from the defined anchors. \citet{casado-garcia_benefits_2020} made a comparison of a series of vanilla models including YOLO and Mask R-CNN which showed good results when these models are pre-trained on TableBank \citep{li_tablebank_2020} (a dataset of document images designed for table recognition) before being fine-tuned and evaluated on more specific datasets. \citet{prasad_cascadetabnet_2020} have proposed what appears to be one of the best performing models overall, a model built from a modified version of Cascade R-CNN that incorporates architectural logic from Mask R-CNN and a version of HRNet aimed at object detection \citep{wang_deep_2020}. HRNet, for High-Resolution Network, maintains a high-resolution representation of images through the process of extracting their features, ensuring a ``semantically richer and spatially more precise'' representation. Note that all these table detection models are based on object instance segmentation algorithms, and most of them are also able to perform table recognition. Besides \cite{lee_newspaper_2020} who propose a Faster R-CNN model trained for extracting visual contents (including headlines, photographs, illustrations, maps, comics, editorial cartoons, and advertisements) in historical newspapers, all of the above models have been trained and evaluated on public datasets. These consist of contemporary, sometimes digital-born documents, and are commonly used for the task of table detection and sometimes that of table recognition. A great overview of these datasets is proposed in the aforementioned survey by \citet{hashmi_current_2021}. \\
To conclude, the research around semantic segmentation models for table detection is slightly less prolific. TableNet by \citet{paliwal_tablenet_2019} is an end-to-end model, based on the CNN model VGG-19 \citep{simonyan_very_2015}, for table detection and recognition that creates masks for tables and columns to then apply a rule-based strategy to detect rows. Another example is \citet{kavasidis_saliency-based_2018}, who propose a model aimed at detecting tables and charts using DL to detect salient regions from document images before they go through a conditional random field. 

\paragraph{Table classification}
To the best of our knowledge, very little work has been done on table classification. We can only cite \citet{ghasemi-gol_tabvec_2018} who create a vector space model to represent the semantic and syntactic structures of web tables in order to classify them by types (relational tables, matrix tables, entity tables, etc.) using their HTML code. Since we are trying to classify tables according to their semantics (and not their structure) using OCRized document images, our problem is actually closer to the more classical tasks of image classification and textual classification for which a huge body of literature exists. In fact, the aforementioned CV and NLP models are perfectly fit to tackle these tasks.

\paragraph{Datasets}
It is well known that the performance of DL models depends on both the quality and quantity of available data. In recent years, massive open-source datasets have emerged to address this need, such as ImageNet \citep{deng_imagenet_2009} and COCO \citep{lin_microsoft_2014}, both consisting of millions of annotated natural images. Some massive domain-specific datasets have also been built; for instance, PubLayNet \citep{zhong_publaynet_2019} and DocBank \citep{li_docbank_2020} gather hundreds of thousands of recent document images annotated only by regions such as title, list or table. Because of the variety of document types, even more specific datasets were created. To name a few in line with the context of this work, the Newspaper Navigator Dataset \citep{lee_newspaper_2020} consists of over 16 million automatically annotated historical newspaper pages, whereas PubTabNet \citep{vedaldi_image-based_2020}, GLOSAT \citep{ziomek_glosat_2021}, ICDAR 2013 \citep{gobel_icdar_2013}, and ICDAR 2019 \citep{gao_icdar_2019} contain images of both recent and historical documents where only tables are tagged. Unfortunately, there are not many historical documents in these datasets, and they are not from newspapers but rather from, e.g., historical logbooks or record books, that are often hand-drawn. 