{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c26087-7d57-4acc-a61f-550b386074c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import boto3\n",
    "import pysolr\n",
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../helpers/\")\n",
    "from impresso_id import *\n",
    "\n",
    "data_path = \"data\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505bd5b-7769-4d68-b03b-2a053d3b5109",
   "metadata": {},
   "source": [
    "# Newspaper dataset of the National Library of Luxembourg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87208d80-13c7-49bd-808c-87d1f977cf4b",
   "metadata": {},
   "source": [
    "This notebook shows the creation of a dataset containing metadata on every items listed as tables by the National Library of Luxembourg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc6990-83a2-470b-b6f7-2139bd4b6cc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Impressio Middle Layer (IML)\n",
    "The IML returns the following fields:\n",
    "'uid', 'type', 'title', 'size', 'nbPages', 'pages', 'isCC', 'excerpt', 'language', 'issue', 'newspaper', 'collections', 'tags', 'country', 'year', 'date', 'isFront', 'accessRight', 'labels', 'contentLineBreaks', 'regionBreaks', 'regions', 'matches'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9446707-7463-4e3c-adc5-121db15c86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iml_token = os.environ['IML_TOKEN']\n",
    "headers = {\"Accept\": \"application/json\",\n",
    "           \"Authorization\": \"Bearer \" + iml_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668a7100-da32-48f2-b2ed-297815633a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62619 results have been retrieved.\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings(record=True):  # hides SSL Certificate error due to verify=False in requests.get()\n",
    "    dataset_iml = dict()\n",
    "\n",
    "    step_size = 1000\n",
    "    offset = 0\n",
    "    while True:\n",
    "        url = f'https://dev.impresso-project.ch/api/search?group_by=articles&filters[0][type]=type&filters[0][q]=tb&offset={offset}&limit=1000'\n",
    "        x = requests.get(url, headers=headers, verify=False)  # NOT ADVISED: verify=False\n",
    "        \n",
    "        for row in json.loads(x.content)['data']:\n",
    "\n",
    "            metadata = dict()\n",
    "            for table in row['regions']:\n",
    "                pid = table['pageUid']\n",
    "                \n",
    "                if pid not in metadata:\n",
    "                    metadata[pid] = dict()\n",
    "                    metadata[pid]['coords'] = {'x': [], 'y': [], 'width': [], 'height': []}\n",
    "                    metadata[pid]['iiifFragmentURL'] = []\n",
    "                    iiifURL = table['iiifFragment'].split('/')\n",
    "                    iiifURL[-4] = 'full'\n",
    "                    iiifURL = '/'.join(iiifURL)\n",
    "                    metadata[pid]['iiifURL'] = iiifURL\n",
    "\n",
    "                metadata[pid]['iiifFragmentURL'].append(table['iiifFragment'])\n",
    "                metadata[pid]['coords']['x'].append(table['coords'][0])\n",
    "                metadata[pid]['coords']['y'].append(table['coords'][1])\n",
    "                metadata[pid]['coords']['width'].append(table['coords'][2])\n",
    "                metadata[pid]['coords']['height'].append(table['coords'][3])\n",
    "\n",
    "            dataset_iml[row['uid']] = metadata\n",
    "\n",
    "        if len(json.loads(x.content)['data']) < step_size:\n",
    "            break\n",
    "        else:\n",
    "            offset += step_size\n",
    "\n",
    "print(f\"{len(dataset_iml)} results have been retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f12c46-4ba4-402b-bef1-a4bde2772fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 table items do not contain any coordinate information.\n"
     ]
    }
   ],
   "source": [
    "empty_tables_iml = {k for k, v in dataset_iml.items() if len(v) == 0}\n",
    "print(f\"{len(empty_tables_iml)} table items do not contain any coordinate information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2d777-f934-4019-a401-9110e45ab80b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some tables do not contain any information, we can therefore safely discard them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014f2562-3ab8-4a90-a3f4-019e9cbdc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in empty_tables_iml:\n",
    "    del dataset_iml[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb5d34c-2e3a-4621-850d-eca67ca775e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tables are spread over multiple pages:\n",
      "luxwort-1896-02-06-a-i0006 over 2 pages\n",
      "luxland-2006-05-05-a-i0111 over 2 pages\n"
     ]
    }
   ],
   "source": [
    "items_over_multiple_pages = [(k, v) for k, v in dataset_iml.items() if len(v) > 1]\n",
    "print(f\"{len(items_over_multiple_pages)} tables are spread over multiple pages:\")\n",
    "for a, b in items_over_multiple_pages:\n",
    "    print(f\"{a} over {len(b)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559ee37-da62-46b9-8f36-cdd13e1454ef",
   "metadata": {},
   "source": [
    "Since this particular case where a table is spread over multiple pages only takes place twice, these tables can be ignored without much incidence later on while largely simplifying upcoming processings. The dataset representation can therefore be simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661ec29a-0062-41b7-895b-a6fac7f3ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in items_over_multiple_pages:\n",
    "    del dataset_iml[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0bb8c4d-cb07-424a-8cf0-e25485261c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item_id, v1 in dataset_iml.items():\n",
    "    page_id, page_dict = list(dataset_iml[item_id].items())[0]\n",
    "    page_dict['pid'] = page_id\n",
    "    dataset_iml[item_id] = page_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b830db1c-b9c5-4e5c-bbcb-62f106debac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62605"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_iml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ff0962-b1dc-4119-a036-e1482bc68adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"metadata_IML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efa625b-2717-47fc-b1e4-b4583951a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, filename + \".json\"), \"w\") as f:\n",
    "    json.dump(dataset_iml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baeff51a-ef83-441b-a9a5-b242ec45c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, filename + \".json\"), \"r\")) as f:\n",
    "    dataset_iml = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca8509-ce64-4850-95ac-d83313ebf72e",
   "metadata": {},
   "source": [
    "### SOLR impresso_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03fb76fe-49c9-41aa-8471-0ecd6ccf8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "solr_url = os.environ['SOLR_URL_DEV']  #https://<username>:<password>@solr.dhlab.epfl.ch/solr\n",
    "solr = pysolr.Solr(solr_url + \"/impresso_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f01518-3009-4e79-8b5a-02927c730178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58026 results have been retrieved.\n"
     ]
    }
   ],
   "source": [
    "# https://solr.apache.org/guide/8_9/pagination-of-results.html (see Deep Pagination)\n",
    "# https://lucidworks.com/post/coming-soon-to-solr-efficient-cursor-based-iteration-of-large-result-sets/\n",
    "\n",
    "dataset_solr = dict()\n",
    "done = False\n",
    "params = {'rows': 1000,\n",
    "          'fl': 'id, rc_plains, pp_plain, content_txt_*',\n",
    "          'fq': 'item_type_s:tb',\n",
    "          'sort': 'id asc',\n",
    "          'cursorMark': '*'}\n",
    "\n",
    "while not done:\n",
    "    results = solr.search('*:*', **params)\n",
    "\n",
    "    for doc in results.docs:\n",
    "        metadata = dict()\n",
    "        content_keys = [k for k in doc.keys() if k.startswith('content_txt_')]\n",
    "        assert(len(content_keys) <= 1)\n",
    "        metadata['text'] = doc[content_keys[0]] if len(content_keys) == 1 else ''\n",
    "        metadata['language'] = content_keys[0][12:] if len(content_keys) == 1 else ''\n",
    "\n",
    "        for row_rc, row_pp in zip(doc['rc_plains'], json.loads(doc['pp_plain'])):  # eval necessary because the list is stored as a string\n",
    "            row_rc = eval(row_rc)  # eval necessary because the dict is stored as a string\n",
    "\n",
    "            assert(row_rc['pid'] == row_pp['id'])\n",
    "            pid = row_rc['pid']\n",
    "\n",
    "            if pid not in metadata:\n",
    "                metadata[pid] = dict()\n",
    "                metadata[pid]['tb_coords'] = {'x': [], 'y': [], 'width': [], 'height': []}\n",
    "                metadata[pid]['text_coords'] = {'x': [], 'y': [], 'width': [], 'height': [], 's': [], 'l': []}\n",
    "\n",
    "            for coord in row_rc['c']:\n",
    "                metadata[pid]['tb_coords']['x'].append(coord[0])\n",
    "                metadata[pid]['tb_coords']['y'].append(coord[1])\n",
    "                metadata[pid]['tb_coords']['width'].append(coord[2])\n",
    "                metadata[pid]['tb_coords']['height'].append(coord[3])\n",
    "\n",
    "            for coord in row_pp['t']:\n",
    "                metadata[pid]['text_coords']['x'].append(coord['c'][0])\n",
    "                metadata[pid]['text_coords']['y'].append(coord['c'][1])\n",
    "                metadata[pid]['text_coords']['width'].append(coord['c'][2])\n",
    "                metadata[pid]['text_coords']['height'].append(coord['c'][3])\n",
    "                metadata[pid]['text_coords']['s'].append(coord['s'])\n",
    "                metadata[pid]['text_coords']['l'].append(coord['l'])\n",
    "\n",
    "        dataset_solr[doc['id']] = metadata\n",
    "            \n",
    "    if params['cursorMark'] == results.nextCursorMark:\n",
    "        done = True\n",
    "    params['cursorMark'] = results.nextCursorMark\n",
    "    \n",
    "print(f\"{len(dataset_solr)} results have been retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e74373-9b37-4e83-8590-50f4d6dfc32e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 table items do not contain any coordinate information\n"
     ]
    }
   ],
   "source": [
    "empty_tables_solr = set()\n",
    "for k1, v1 in dataset_solr.items():\n",
    "    for k2, v2 in v1.items():\n",
    "        if k2 not in {'text', 'language'}:\n",
    "            if len(v2['tb_coords']['x']) == 0:\n",
    "                empty_tables_solr.add(k1)\n",
    "                \n",
    "print(f\"{len(empty_tables_solr)} table items do not contain any coordinate information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d116376-ed98-4158-8ae1-91a3c61c3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in empty_tables_solr:\n",
    "    del dataset_solr[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a287ce39-53f6-4857-bf19-3de8a5da5733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tables are spread over multiple pages:\n",
      "luxland-2006-05-05-a-i0111 over 2 pages\n",
      "luxwort-1896-02-06-a-i0006 over 2 pages\n"
     ]
    }
   ],
   "source": [
    "items_over_multiple_pages = [(k, v) for k, v in dataset_solr.items() if len(v) > 3]\n",
    "print(f\"{len(items_over_multiple_pages)} tables are spread over multiple pages:\")\n",
    "for a, b in items_over_multiple_pages:\n",
    "    print(f\"{a} over {len(b) - 2} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5190cb27-24ee-4be9-8ecf-cd8ebeb3a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in items_over_multiple_pages:\n",
    "    del dataset_solr[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabc4921-d6ee-4034-9759-03d211b99fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for item_id, v1 in dataset_solr.items():\n",
    "    page_id, page_dict = [(k, v) for k, v in dataset_solr[item_id].items() if k not in {'text', 'language'}][0]\n",
    "    page_dict['pid'] = page_id\n",
    "    page_dict['text'] = dataset_solr[item_id]['text']\n",
    "    page_dict['language'] = dataset_solr[item_id]['language']\n",
    "    dataset_solr[item_id] = page_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8828feda-e712-4894-b6d9-d6d1ac8f1782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_solr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a31d315f-1139-412e-b8ee-80cc2660ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"metadata_SOLR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a747be-54a9-4c72-a8e3-47ea9dd66009",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, filename + \".json\"), \"w\") as f:\n",
    "    json.dump(dataset_solr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb67b8d-604c-424f-aa8b-008227cddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, filename + \".json\"), \"r\")) as f:\n",
    "    dataset_solr = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa205f5a-dc96-4c9b-ba26-1472888c958e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c414c1e4-a081-4460-bee9-5132667824f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset_solr.keys()) == set(dataset_iml.keys()).intersection(set(dataset_solr.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f723a42-b337-4b3a-a1a3-dbf3569d3423",
   "metadata": {},
   "source": [
    "The data from SOLR is a subset of the data from IML. Since the data from SOLR contains more information that might be relevant later on, such as text information, data from IML is discarded. Since I was unsure of the origin of this difference, and the data from SOLR is considered as the main source, I did not investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca5b95ba-266f-4dae-af58-fe9ba83f8962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = set(dataset_iml.keys()).difference(set(dataset_solr.keys()))\n",
    "\n",
    "for k in difference:\n",
    "    del dataset_iml[k]\n",
    "    \n",
    "print(len(dataset_solr))\n",
    "dataset_solr.keys() == dataset_iml.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd890a-c238-4b78-a735-7fa911a3f575",
   "metadata": {},
   "source": [
    "NB: To whoever reads this, this difference should be investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e661cd-b13e-4266-8663-5354cfcee0b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export\n",
    "The datasets are merged and exported. Each image can now be retrieved from the IIIF of the National Library of Luxembourg, and additional information about the OCR and the location of the tables is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cdfa2e6-f7b5-4ed3-a4d0-cfa506f7c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL_metadata = dict()\n",
    "NLL_metadata_lite = dict()\n",
    "for k in dataset_iml.keys():\n",
    "    \n",
    "    table_metadata = dict()\n",
    "    table_metadata_lite = dict()\n",
    "    table_metadata = dataset_solr[k].copy()\n",
    "    table_metadata['iiifURL'] = dataset_iml[k]['iiifURL']\n",
    "    table_metadata['iiifFragmentURL'] = dataset_iml[k]['iiifFragmentURL']\n",
    "\n",
    "    table_metadata_lite = table_metadata.copy()\n",
    "    del table_metadata_lite['text_coords']\n",
    "    del table_metadata_lite['text']\n",
    "    del table_metadata_lite['language']\n",
    "\n",
    "    NLL_metadata[k] = table_metadata    \n",
    "    NLL_metadata_lite[k] = table_metadata_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40c8a594-e25b-4b2d-8e5a-2966a9c5d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, \"NLL_metadata.json\"), \"w\")) as f:\n",
    "    json.dump(NLL_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d08755ef-07f2-43f1-b1d7-5ba552dbb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, \"NLL_metadata_lite.json\"), \"w\")) as f:\n",
    "    json.dump(NLL_metadata_lite, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b31bb598-93ae-45d4-8492-77598b4f2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, \"NLL_metadata.json\"), \"r\")) as f:\n",
    "    NLL_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d64bc33-b127-43f7-ad32-e808870484a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, \"NLL_metadata_lite.json\"), \"r\")) as f:\n",
    "    NLL_metadata_lite = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1c69a-d70f-4c7d-b4bf-5983e1e20768",
   "metadata": {},
   "source": [
    "### Additional exports\n",
    "Specific dataset containing only a subset of the data are then created for the different steps of the pipeline used in [impresso-images](https://github.com/impresso/impresso-images)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbac82-8065-4914-b4a1-82740c5c9dd6",
   "metadata": {},
   "source": [
    "#### Step 1: ID-IIIF pairs for *extract_images_iiif.py*\n",
    "This dataset is necessary to indicate which images to download and under what name they must be referred to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bc71ba0-4da1-443c-b2a9-a0d18201aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"NLL_id_iiif_pairs\"\n",
    "NLL_id_iiif_pairs = {v['pid']: v['iiifURL'] for k, v in NLL_metadata_lite.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "641a34e1-d9f5-4237-8834-f8fd5f4aab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, filename + \".jsonl\"), \"w\")) as f:\n",
    "    for k, v in NLL_id_iiif_pairs.items():\n",
    "        json.dump({'id': k, 'iiif_url': v}, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27e589-0e1a-44a4-bb7a-a12795e641e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: coordinates for *crop_images.py*\n",
    "This dataset is necessary to give the coordinates where to crop the full images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87bc861c-43ad-4491-89c2-b37e64414cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"NLL_cropping_coordinates\"\n",
    "NLL_cropping_coordinates = dict()\n",
    "for k, v in NLL_metadata_lite.items():\n",
    "    pid = v['pid']\n",
    "    if pid not in NLL_cropping_coordinates:\n",
    "        NLL_cropping_coordinates[pid] = dict()\n",
    "        \n",
    "    coords = v['tb_coords']\n",
    "    NLL_cropping_coordinates[pid][k] = list(zip(coords['x'], coords['y'], coords['width'], coords['height']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba6159ee-bcf8-458d-b793-683db14c4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, filename + \".json\"), \"w\")) as f:\n",
    "    json.dump(NLL_cropping_coordinates, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21374b-11b8-469f-aa27-384d39255b8e",
   "metadata": {},
   "source": [
    "#### Step 3: additional metadata for *import_visual_signatures.py*\n",
    "This dataset contains metadata to be stored on SOLR alongside the visual signatures of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d12baa39-e74a-4e45-a9c4-cde5ddd7a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"NLL_metadata_solr\"\n",
    "\n",
    "NLL_metadata_solr = dict()\n",
    "for k, v in NLL_metadata_lite.items():\n",
    "    table_solr_metadata = dict()\n",
    "    \n",
    "    c = v['tb_coords']\n",
    "    coords = []\n",
    "    for x, y, width, height in zip(c['x'], c['y'], c['width'], c['height']):\n",
    "        coords.append(str((x, y, width, height)))  # SOLR doesn't accept list of list of int, hence the use of a list of strings\n",
    "        \n",
    "    table_solr_metadata[\"coords_ss\"] = coords\n",
    "    table_solr_metadata[\"iiif_link_s\"] = v['iiifURL']\n",
    "    table_solr_metadata[\"iiif_fragment_link_ss\"] = v['iiifFragmentURL']\n",
    "    table_solr_metadata[\"meta_day_i\"] = get_day(k)\n",
    "    table_solr_metadata[\"meta_month_i\"] = get_month(k)\n",
    "    table_solr_metadata[\"meta_year_i\"] = get_year(k)\n",
    "    table_solr_metadata[\"meta_journal_s\"] = get_journal(k)\n",
    "    table_solr_metadata[\"meta_date_dt\"] = get_date(k).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    table_solr_metadata[\"item_type_s\"] = \"tb\"\n",
    "    table_solr_metadata[\"meta_ed_s\"] = get_edition(k)\n",
    "    table_solr_metadata[\"meta_issue_id_s\"] = get_meta_issue_id(k)\n",
    "    table_solr_metadata[\"page_nb_i\"] = get_page(v['pid'])\n",
    "    table_solr_metadata[\"front_b\"] = is_front_page(v['pid'])\n",
    "    \n",
    "    NLL_metadata_solr[k] = table_solr_metadata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79a51dd5-2edc-43c6-8ece-5d3ed1933d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(os.path.join(data_path, filename + \".json\"), \"w\")) as f:\n",
    "    json.dump(NLL_metadata_solr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd303e6-a963-4a54-bf23-fc517ef2095d",
   "metadata": {},
   "source": [
    "#### Step 4: S3 storage metadata for the GUI\n",
    "This dataset maps the location of each image to each file in the dedicated S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d344009-4d42-4cd2-bc22-664525319427",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                    endpoint_url='https://' + os.environ.get(\"S3_ENDPOINT\", 'os.zhdk.cloud.switch.ch'),\n",
    "                    aws_access_key_id=os.environ.get(\"SE_ACCESS_KEY\", None),\n",
    "                    aws_secret_access_key=os.environ.get(\"SE_SECRET_KEY\", None))\n",
    "\n",
    "bucket = s3.Bucket(\"impresso-tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f907027-88f4-424c-a4ac-4a677bb63c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = bucket.Object(\"images-packed/image-ids-metadata-0.json\")\n",
    "images_metadata = []\n",
    "for line in obj.get()['Body'].iter_lines():\n",
    "    images_metadata.append(json.loads(line))\n",
    "images_metadata = pd.DataFrame(images_metadata)\n",
    "    \n",
    "obj = bucket.Object(\"table-images-packed/image-ids-metadata-0.json\")\n",
    "table_images_metadata = []\n",
    "for line in obj.get()['Body'].iter_lines():\n",
    "    table_images_metadata.append(json.loads(line))\n",
    "table_images_metadata = pd.DataFrame(table_images_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40a21a24-73eb-4c15-8cf2-8768c0b1749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL_metadata_s3 = pd.DataFrame().from_dict(NLL_metadata_lite, orient='index').drop(['tb_coords', 'iiifURL', 'iiifFragmentURL'], axis=1)\n",
    "NLL_metadata_s3 = pd.merge(NLL_metadata_s3, table_images_metadata, left_index=True, right_on='id').rename({'path': 'id_loc', 'id': 'tb_id'}, axis=1)\n",
    "NLL_metadata_s3 = pd.merge(NLL_metadata_s3, images_metadata, left_on='pid', right_on='id').rename({'path': 'pid_loc'}, axis=1).drop('id', axis=1).rename({'tb_id': 'id'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd0c89bd-8402-49b9-a137-863c86beb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL_metadata_s3['id_loc'] = NLL_metadata_s3['id_loc'].apply(lambda x: x[16:])\n",
    "NLL_metadata_s3['pid_loc'] = NLL_metadata_s3['pid_loc'].apply(lambda x: x[16:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06b43efe-ed20-4109-8bd1-3ec0b9a9d025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58011, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>id</th>\n",
       "      <th>id_loc</th>\n",
       "      <th>pid_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luxzeit1858-1858-03-10-a-p0001</td>\n",
       "      <td>luxzeit1858-1858-03-10-a-i0018</td>\n",
       "      <td>table-images-packed/image-data-00711.jsonl.gz</td>\n",
       "      <td>images-packed/image-data-00711.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>luxzeit1858-1858-03-10-a-p0001</td>\n",
       "      <td>luxzeit1858-1858-03-10-a-i0019</td>\n",
       "      <td>table-images-packed/image-data-00711.jsonl.gz</td>\n",
       "      <td>images-packed/image-data-00711.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avenirgdl-1871-07-25-a-p0004</td>\n",
       "      <td>avenirgdl-1871-07-25-a-i0033</td>\n",
       "      <td>table-images-packed/image-data-00079.jsonl.gz</td>\n",
       "      <td>images-packed/image-data-00079.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avenirgdl-1871-07-25-a-p0004</td>\n",
       "      <td>avenirgdl-1871-07-25-a-i0026</td>\n",
       "      <td>table-images-packed/image-data-00079.jsonl.gz</td>\n",
       "      <td>images-packed/image-data-00079.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avenirgdl-1871-07-25-a-p0004</td>\n",
       "      <td>avenirgdl-1871-07-25-a-i0031</td>\n",
       "      <td>table-images-packed/image-data-00079.jsonl.gz</td>\n",
       "      <td>images-packed/image-data-00079.jsonl.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pid                              id  \\\n",
       "0  luxzeit1858-1858-03-10-a-p0001  luxzeit1858-1858-03-10-a-i0018   \n",
       "1  luxzeit1858-1858-03-10-a-p0001  luxzeit1858-1858-03-10-a-i0019   \n",
       "2    avenirgdl-1871-07-25-a-p0004    avenirgdl-1871-07-25-a-i0033   \n",
       "3    avenirgdl-1871-07-25-a-p0004    avenirgdl-1871-07-25-a-i0026   \n",
       "4    avenirgdl-1871-07-25-a-p0004    avenirgdl-1871-07-25-a-i0031   \n",
       "\n",
       "                                          id_loc  \\\n",
       "0  table-images-packed/image-data-00711.jsonl.gz   \n",
       "1  table-images-packed/image-data-00711.jsonl.gz   \n",
       "2  table-images-packed/image-data-00079.jsonl.gz   \n",
       "3  table-images-packed/image-data-00079.jsonl.gz   \n",
       "4  table-images-packed/image-data-00079.jsonl.gz   \n",
       "\n",
       "                                   pid_loc  \n",
       "0  images-packed/image-data-00711.jsonl.gz  \n",
       "1  images-packed/image-data-00711.jsonl.gz  \n",
       "2  images-packed/image-data-00079.jsonl.gz  \n",
       "3  images-packed/image-data-00079.jsonl.gz  \n",
       "4  images-packed/image-data-00079.jsonl.gz  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(NLL_metadata_s3.shape)\n",
    "NLL_metadata_s3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9e1c381-9117-4947-a653-fd91a9bd77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL_metadata_s3.to_parquet(os.path.join(data_path, \"NLL_metadata_s3.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff05d15-eba1-4259-9f84-5d462c9eb6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "pdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
