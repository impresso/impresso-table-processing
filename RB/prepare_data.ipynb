{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf476f6c-b990-41ea-8737-234555aa579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from shutil import copy\n",
    "from pathlib import Path\n",
    "\n",
    "zenodo_path = \"zenodo\"\n",
    "metadata_path = \"metadata\"\n",
    "data_path = \"data\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68107b4-bca5-4d19-81ef-0bde9131c515",
   "metadata": {},
   "source": [
    "# Raphaël Barman: Stocks dataset\n",
    "This notebook extracts every annotated stock tables from Raphaël Barman's dataset: https://zenodo.org/record/3706863."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873be859-4be7-4d20-ab3f-b95e1f42024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(zenodo_path, \"GDL.json\"), \"r\") as f:\n",
    "    GDL_annotations = json.load(f)\n",
    "    \n",
    "with open(os.path.join(zenodo_path, \"IMP.json\"), \"r\") as f:\n",
    "    IMP_annotations = json.load(f)\n",
    "    \n",
    "with open(os.path.join(zenodo_path, \"JDG.json\"), \"r\") as f:\n",
    "    JDG_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d89b9c-8c81-4c9b-8cfa-a6e77579702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDL_annotations = {k: v for k, v in GDL_annotations['_via_img_metadata'].items() if len(v['regions']) > 0}\n",
    "IMP_annotations = {k: v for k, v in IMP_annotations['_via_img_metadata'].items() if len(v['regions']) > 0}\n",
    "JDG_annotations = {k: v for k, v in JDG_annotations['_via_img_metadata'].items() if len(v['regions']) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121ac2be-b8dd-4589-a8f9-e30d6bb9a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDL has 290 stocks tables.\n",
      "IMP has 109 stocks tables.\n",
      "JDG has 429 stocks tables.\n"
     ]
    }
   ],
   "source": [
    "def filter_stocks(annotations):\n",
    "    stocks_annotations = dict()\n",
    "    for k, v in annotations.items():\n",
    "        for region in v['regions']:\n",
    "            v['regions'] = [x for x in v['regions'] if x['region_attributes']['label'] == 'stocks']\n",
    "\n",
    "        if len(v['regions']) > 0:\n",
    "            stocks_annotations[k] = v\n",
    "    \n",
    "    return stocks_annotations\n",
    "\n",
    "GDL_stocks = filter_stocks(GDL_annotations)\n",
    "print(f\"GDL has {sum([len(v['regions']) for k,v in GDL_stocks.items()])} stocks tables.\")\n",
    "IMP_stocks = filter_stocks(IMP_annotations)\n",
    "print(f\"IMP has {sum([len(v['regions']) for k,v in IMP_stocks.items()])} stocks tables.\")\n",
    "JDG_stocks = filter_stocks(JDG_annotations)\n",
    "print(f\"JDG has {sum([len(v['regions']) for k,v in JDG_stocks.items()])} stocks tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1ba5e8-0678-4257-b74f-8079d9e8d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method extracts all the newspaper pages that contain tables, as well as the tables\n",
    "# Generates a file named RB_metadata.parquet necessary for the GUI\n",
    "# Generates a file named RB_metadata_images.json storing the size of each image\n",
    "def generate_dataset(annotations, journal_name):\n",
    "\n",
    "    input_path = os.path.join(zenodo_path, \"images/images\")\n",
    "    export_path = data_path\n",
    "            \n",
    "    cropped_images_export_path = os.path.join(export_path, \"cropped images\")\n",
    "    os.makedirs(cropped_images_export_path, exist_ok=True)\n",
    "    full_images_export_path = os.path.join(export_path, \"full images\")\n",
    "    os.makedirs(full_images_export_path, exist_ok=True)\n",
    "\n",
    "    metadata = pd.DataFrame(columns=['id', 'pid', 'id_loc', 'pid_loc'])\n",
    "    metadata_images = {}\n",
    "        \n",
    "    export_annotations = annotations.copy()\n",
    "    for k, v in annotations.items():\n",
    "        name = v['filename']\n",
    "        copy(os.path.join(input_path, journal_name, name), full_images_export_path)\n",
    "        image = Image.open(os.path.join(input_path, journal_name, name))\n",
    "        metadata_images[k[:-2]] = {'height': image.height,\n",
    "                              'width': image.width,\n",
    "                              'resized_height': image.height,\n",
    "                              'resized_width': image.width}\n",
    "        \n",
    "        regions_copy = v['regions']\n",
    "        for i, region in enumerate(v['regions']):\n",
    "            try:\n",
    "                cropped_image_id = k + f\"-{i}\"\n",
    "                cropped_image_export_path = os.path.join(cropped_images_export_path, cropped_image_id + \".jpg\")\n",
    "                metadata.loc[len(metadata)] = [cropped_image_id, \n",
    "                                               k, \n",
    "                                               os.path.abspath(cropped_image_export_path), \n",
    "                                               os.path.abspath(os.path.join(full_images_export_path, name))]\n",
    "            \n",
    "                if not Path(cropped_image_export_path).exists():\n",
    "                    if region['shape_attributes']['name'] == 'rect':\n",
    "                        x = region['shape_attributes']['x']\n",
    "                        y = region['shape_attributes']['y']\n",
    "                        width = region['shape_attributes']['width']\n",
    "                        height = region['shape_attributes']['height']\n",
    "                        cropped_image = image.crop((x, y, x + width, y + height))\n",
    "                        cropped_image.save(cropped_image_export_path)\n",
    "\n",
    "                    elif region['shape_attributes']['name'] == 'polygon':\n",
    "                        # https://stackoverflow.com/questions/48301186/cropping-concave-polygon-from-image-using-opencv-python\n",
    "                        \n",
    "                        # https://stackoverflow.com/questions/33548956/detect-avoid-premature-end-of-jpeg-in-cv2-python\n",
    "                        with open(os.path.join(input_path, journal_name, name), 'rb') as f:\n",
    "                            check_chars = f.read()[-2:]\n",
    "                        if check_chars != b'\\xff\\xd9':\n",
    "                            print('Not complete image')\n",
    "                            raise OSError\n",
    "                        else:\n",
    "                            image_cv = cv2.imread(os.path.join(input_path, journal_name, name))\n",
    "\n",
    "                        all_points_x = region['shape_attributes']['all_points_x']\n",
    "                        all_points_y = region['shape_attributes']['all_points_y']\n",
    "                        points = np.array([[x, y] for (x, y) in zip(all_points_x, all_points_y)])\n",
    "\n",
    "                        ## (1) Crop the bounding rect\n",
    "                        rect = cv2.boundingRect(points)\n",
    "                        x, y, w, h = rect\n",
    "                        cropped_image_cv = image_cv[y:(y + h), x:(x + w)].copy()\n",
    "\n",
    "                        ## (2) make mask\n",
    "                        points = points - points.min(axis=0)\n",
    "                        mask = np.zeros(cropped_image_cv.shape[:2], np.uint8)\n",
    "                        cv2.drawContours(mask, [points], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "                        ## (3) do bit-op\n",
    "                        dst = cv2.bitwise_and(cropped_image_cv, cropped_image_cv, mask=mask)\n",
    "\n",
    "                        cv2.imwrite(cropped_image_export_path, dst)\n",
    "                    else:\n",
    "                        print(f\"Could not process region of type {region['shape_attributes']['name']}.\")\n",
    "            except OSError as e:\n",
    "                annotations[k]['regions'].remove(region)\n",
    "                print(f\"{e}: {k} and {region}\")\n",
    "                \n",
    "    annotations_path = os.path.join(export_path, \"via_annotations_RB.json\")\n",
    "    if Path(annotations_path).exists():\n",
    "        with open(annotations_path, \"r\") as f:\n",
    "            export_annotations.update(json.load(f))\n",
    "            \n",
    "    with open(annotations_path, \"w\") as f:\n",
    "        json.dump(export_annotations, f)\n",
    "        \n",
    "    metadata_images_path = os.path.join(export_path, \"RB_metadata_images.json\")\n",
    "    if Path(metadata_images_path).exists():\n",
    "        with open(metadata_images_path, \"r\") as f:\n",
    "            metadata_images.update(json.load(f))\n",
    "            \n",
    "    with open(metadata_images_path, \"w\") as f:\n",
    "        json.dump(metadata_images, f)\n",
    "\n",
    "    metadata_path = os.path.join(export_path, \"RB_metadata.parquet\")\n",
    "    if Path(metadata_path).exists():\n",
    "        metadata = pd.concat([metadata, pd.read_parquet(metadata_path)]).reset_index(drop=True)\n",
    "\n",
    "    metadata.to_parquet(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d527f06e-4d48-4435-98ec-2cd7573aebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image file is truncated (32 bytes not processed): GDL-1987-03-24-a-p0007-1 and {'shape_attributes': {'name': 'rect', 'x': 974, 'y': 710, 'width': 292, 'height': 179}, 'region_attributes': {'label': 'stocks'}}\n",
      "Not complete image\n",
      ": GDL-1987-03-24-a-p0007-1 and {'shape_attributes': {'name': 'polygon', 'all_points_x': [661, 664, 661, 1265, 1266, 977, 971], 'all_points_y': [1416, 1408, 896, 903, 1478, 1479, 1415]}, 'region_attributes': {'label': 'stocks'}}\n",
      "image file is truncated (32 bytes not processed): GDL-1987-03-24-a-p0007-1 and {'shape_attributes': {'name': 'rect', 'x': 974, 'y': 1507, 'width': 295, 'height': 187}, 'region_attributes': {'label': 'stocks'}}\n"
     ]
    }
   ],
   "source": [
    "generate_dataset(GDL_stocks, \"GDL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e9b132-ca31-4ff2-9ed3-7fbe46fd7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(IMP_stocks, \"IMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892ca716-a94d-4e15-9d01-a3daa83e5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(JDG_stocks, \"JDG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4985c8-ae6c-4348-8061-6503005055a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "pdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
